  
#========================================================================================
#Kafka 실행(zookeeper -> kafka -> topic 생성 -> consumer 실행)
#========================================================================================
kafka-server-start.bat c:\kafka\config\server.properties
zookeeper-server-start.bat c:\kafka\config\zookeeper.properties

kafka-topics.bat --zookeeper localhost:2181 --topic erestaurant --create --partitions 1 --replication-factor 1
kafka-topics.bat --list --zookeeper localhost:2181
kafka-console-consumer.bat --bootstrap-server http://localhost:9092 --topic erestaurant --from-beginning


#========================================================================================
#서비스 실행
#========================================================================================
cd hall
mvn spring-boot:run

cd kitchen
mvn spring-boot:run

cd payment
mvn spring-boot:run

cd workercenter
mvn spring-boot:run

cd gateway
mvn spring-boot:run

#========================================================================================
#시나리오 검증
#========================================================================================
###[주문]
http POST http://52.231.200.152:8080/orders employeeCardNo=1 menuname="불고기덮밥" amount=5000
http POST http://52.231.200.152:8080/orders employeeCardNo=2 menuname="김치찌개" amount=4500
http POST http://52.231.200.152:8080/orders employeeCardNo=3 menuname="돈까스" amount=6000
http POST http://52.231.200.152:8080/orders employeeCardNo=4 menuname="양고기" amount=86000

###[요리 및 결제]
http PATCH http://52.231.200.152:8080/cooks/1 status="요리완료"

###[확인]
http GET http://52.231.200.152:8080/orders
http GET http://52.231.200.152:8080/cooks
http GET http://52.231.200.152:8080/payments
http GET http://52.231.200.152:8080/mypages

#========================================================================================
[helm 설치(v3.6.1)]
#========================================================================================
root@labs-1501929124:/home/project#
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh

#v3.6.1 설치 확인
helm version

#========================================================================================
[#Azure 관련]
-------------------------------
ㅇ 접속계정 : user23@gkn2021hotmail.onmicrosoft.com
ㅇ 리소스 그룹 : skcc-user23-rsrcgrp
ㅇ Kubernetes 클러스터 이름 : skcc-user23-aks
  ※ aks : Azure Kubernetes Service
ㅇ 컨테이너 레지스트리(ACR) 이름 : skccuser23
  ※ ACR : Azure Container Registry
#========================================================================================
#Azure 연결
az login

#azure shell 에서 클러스터 연결
#az aks get-credentials --resource-group (user01_resource_group) --name (user01_cluster)
chmod 600 /root/.kube/config
az aks get-credentials --resource-group skcc-user23-rsrcgrp --name skcc-user23-aks

kubectl get all

#AKS와 ACR 연결
#az aks update -n [azure-cluster-name] -g [azure-resource-Group-name] --attach-acr [azure-acr-name]
az aks update -n skcc-user23-aks -g skcc-user23-rsrcgrp --attach-acr skccuser23

#========================================================================================
[KAFKA 설치]
#========================================================================================
# helm 의 설치관리자를 위한 시스템 사용자 생성
kubectl --namespace kube-system create sa tiller
kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

helm repo add incubator https://charts.helm.sh/incubator
helm repo update
kubectl create ns kafka
helm install my-kafka --namespace kafka incubator/kafka


kubectl get namespace
kubectl -n kafka exec my-kafka-0 -- /usr/bin/kafka-topics --zookeeper my-kafka-zookeeper:2181 --topic erestaurant --create --partitions 3 --replication-factor 3
kubectl -n kafka exec my-kafka-0 -- /usr/bin/kafka-topics --zookeeper my-kafka-zookeeper:2181 --list

#확인
#kubectl -n kafka exec -ti my-kafka-0 -- /usr/bin/kafka-console-producer --broker-list my-kafka:9092 --topic erestaurant
kubectl -n kafka exec -ti my-kafka-0 -- /usr/bin/kafka-console-consumer --bootstrap-server my-kafka:9092 --topic erestaurant --from-beginning

#######################이하, Pass####################################################################
#helm del --purge my-kafka
#----------------------------
kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
위 명령어를 실행하면 아래와 같이 default storage가 두 개로 설정되는 오류가 발생

root@labs--1975389722:/home/project# kubectl get sc
NAME                        PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
azurefile                   kubernetes.io/azure-file   Delete          Immediate              true                   22h
azurefile-premium           kubernetes.io/azure-file   Delete          Immediate              true                   22h
default (default)           kubernetes.io/azure-disk   Delete          WaitForFirstConsumer   true                   22h
managed-premium (default)   kubernetes.io/azure-disk   Delete          WaitForFirstConsumer   true                   22h
#----------------------------
>>> 해결책은 아래 Command 실행
kubectl patch storageclass managed-premium -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
####################################################################################################


#========================================================================================
#소스가져오기
#========================================================================================
git clone https://github.com/choiyeonshik/e-restaurant.git

#========================================================================================
#네임스페이스 만들기
#========================================================================================
kubectl create ns choi
kubectl get ns
kubectl get all -n choi

#========================================================================================
#Deployment & Build & Push
#========================================================================================
cd /home/project/e-restaurant/hall
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/hall:v9 .
kubectl create deploy hall --image=skccuser23.azurecr.io/hall:v8 -n choi

kubectl delete --all deployment,pod,service hall -n choi

kubectl describe pod/hall-7cbb9cccb5-ckcd4 -n choi
kubectl logs -f pod/hall-68884b6b88-snqrs -c hall -n choi

#yaml 이용(이하, 동문)
#kubectl create -f ./kubernetes/deployment.yml -n choi
#kubectl create -f ./kubernetes/service.yaml -n choi
#kubectl apply -f ./kubernetes/deployment.yml -n choi
#kubectl apply -f ./kubernetes/service.yaml -n choi

cd /home/project/e-restaurant/kitchen
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/kitchen:v3 .
kubectl create deploy kitchen --image=skccuser23.azurecr.io/kitchen:v3 -n choi

cd /home/project/e-restaurant/payment
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/payment:v1 .
kubectl create deploy payment --image=skccuser23.azurecr.io/payment:v1 -n choi

cd /home/project/e-restaurant/workercenter
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/workercenter:v1 .
kubectl create deploy workercenter --image=skccuser23.azurecr.io/workercenter:v1 -n choi

cd /home/project/e-restaurant/gateway
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/gateway:v1 .
kubectl create deploy gateway --image=skccuser23.azurecr.io/gateway:v1 -n choi

#확인
kubectl get all -n choi
kubectl describe pod/gateway-7cffc5cd4d-bdbhx -n choi
kubectl logs -f pod/gateway-7cffc5cd4d-bdbhx -n choi

#이후에는 apply로 처리
az acr build --registry skccuser23 --image skccuser23.azurecr.io/gateway:v1 .
#kubectl create -f ./kubernetes/deployment.yml -n choi
#kubectl create -f ./kubernetes/service.yaml -n choi
#kubectl apply -f ./kubernetes/deployment.yml -n choi
#kubectl apply -f ./kubernetes/service.yaml -n choi


kubectl expose deploy hall --type=ClusterIP --port=8080 -n choi
kubectl expose deploy kitchen --type=ClusterIP --port=8080 -n choi
kubectl expose deploy payment --type=ClusterIP --port=8080 -n choi
kubectl expose deploy workercenter --type=ClusterIP --port=8080 -n choi
kubectl expose deploy gateway --type=LoadBalancer --port=8080 -n choi

#========================================================================================
#Config Map (application yaml 수정 -> deployment 적용 -> configmap 생성 순으로 진행)
#========================================================================================
kubectl create configmap configmap-url --from-literal=CONFIGMAP_KITCHEN_URL=http://kitchen:8080 -n choi
kubectl get configmap configmap-url -o yaml -n choi

#========================================================================================
#Circuit Breaker
#========================================================================================
cd /home/project/e-restaurant/hall
mvn clean
mvn compile
mvn package

az acr build --registry skccuser23 --image skccuser23.azurecr.io/hall:v8 .
kubectl apply -f ./kubernetes/deployment.yml -n choi

#kubectl run siege --image=apexacme/siege-nginx -n choi
#kubectl get pod -n choi

kubectl exec -it pod/siege-d484db9c-6f6h2 -c siege -n choi -- /bin/bash
siege -c10 -t120S -v --content-type "application/json" 'http://hall:8080/orders POST {"employeeCardNo": "2", "menuname":"된장찌개", "menuname":"4500"}'


#========================================================================================
#AutoScale(HPA)
#========================================================================================
kubectl autoscale deployment hall --cpu-percent=20 --min=1 --max=3 -n choi

kubectl run siege --image=apexacme/siege-nginx -n choi
kubectl get pod -n choi

kubectl exec -it pod/siege-d484db9c-6f6h2 -c siege -n choi -- /bin/bash
siege -c200 -t120S -v --content-type "application/json" 'http://hall:8080/orders POST {"employeeCardNo": "1", "menuname":"불고기덮밥", "menuname":"5000"}'

#kubectl delete hpa hall

#========================================================================================
#Liveness Probe
#========================================================================================
kubectl describe pod/nginx3-7cffc5cd4d-bdbhx -n choi

kubectl exec -it pod/siege-d484db9c-6f6h2 -c siege -n choi -- /bin/bash
siege -c1 -t30S -v --content-type "application/json" 'http://hall:8080/orders POST {"employeeCardNo": "4", "menuname":"돈까스", "menuname":"5500"}'


#========================================================================================
#Readiness Probe
#========================================================================================
kubectl apply -f kubernetes/deployment.yml -n choi

kubectl describe pod/nginx3-7cffc5cd4d-bdbhx -n choi

kubectl exec -it pod/siege-d484db9c-6f6h2 -c siege -n choi -- /bin/bash
siege -c1 -t10S -v --content-type "application/json" 'http://hall:8080/orders POST {"employeeCardNo": "2", "menuname":"된장찌개", "menuname":"4500"}'
