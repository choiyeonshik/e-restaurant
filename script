  
#========================================================================================
#Kafka 실행(zookeeper -> kafka -> topic 생성 -> consumer 실행)
#========================================================================================
kafka-server-start.bat c:\kafka\config\server.properties
zookeeper-server-start.bat c:\kafka\config\zookeeper.properties

kafka-topics.bat --zookeeper localhost:2181 --topic erestaurant --create --partitions 1 --replication-factor 1
kafka-topics.bat --list --zookeeper localhost:2181
kafka-console-consumer.bat --bootstrap-server http://localhost:9092 --topic erestaurant --from-beginning


#========================================================================================
#서비스 실행
#========================================================================================
cd hall
mvn spring-boot:run

cd kitchen
mvn spring-boot:run

cd payment
mvn spring-boot:run

cd workercenter
mvn spring-boot:run

cd gateway
mvn spring-boot:run

#========================================================================================
#시나리오 검증
#========================================================================================
###[주문]
http POST http://localhost:8088/orders employeeCardNo=1 menuname="불고기덮밥" amount=5000
http POST http://localhost:8088/orders employeeCardNo=2 menuname="김치찌개" amount=4500
http POST http://localhost:8088/orders employeeCardNo=3 menuname="돈까스" amount=6000

###[요리 및 결제]
http PATCH http://localhost:8088/cooks/1 status="요리완료"

###[확인]
http GET http://localhost:8088/orders
http GET http://localhost:8088/cooks
http GET http://localhost:8088/payments
http GET http://localhost:8088/mypages

#========================================================================================
[helm 설치(v3.6.1)]
#========================================================================================
root@labs-1501929124:/home/project#
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh

#v3.6.1 설치 확인
helm version

#========================================================================================
[#Azure 관련]
-------------------------------
ㅇ 접속계정 : user23@gkn2021hotmail.onmicrosoft.com
ㅇ 리소스 그룹 : skcc-user23-rsrcgrp
ㅇ Kubernetes 클러스터 이름 : skcc-user23-aks
  ※ aks : Azure Kubernetes Service
ㅇ 컨테이너 레지스트리(ACR) 이름 : skccuser23
  ※ ACR : Azure Container Registry
#========================================================================================
#Azure 연결
az login

#azure shell 에서 클러스터 연결
#az aks get-credentials --resource-group (user01_resource_group) --name (user01_cluster)
chmod 600 /root/.kube/config
az aks get-credentials --resource-group skcc-user23-rsrcgrp --name skcc-user23-aks

kubectl get all

#AKS와 ACR 연결
#az aks update -n [azure-cluster-name] -g [azure-resource-Group-name] --attach-acr [azure-acr-name]
az aks update -n skcc-user23-aks -g skcc-user23-rsrcgrp --attach-acr skccuser23

#========================================================================================
[KAFKA 설치]
#========================================================================================
# helm 의 설치관리자를 위한 시스템 사용자 생성
kubectl --namespace kube-system create sa tiller
kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

helm repo add incubator https://charts.helm.sh/incubator
helm repo update
kubectl create ns kafka
helm install my-kafka --namespace kafka incubator/kafka


kubectl get namespace
kubectl -n kafka exec my-kafka-0 -- /usr/bin/kafka-topics --zookeeper my-kafka-zookeeper:2181 --topic erestaurant --create --partitions 3 --replication-factor 3
kubectl -n kafka exec my-kafka-0 -- /usr/bin/kafka-topics --zookeeper my-kafka-zookeeper:2181 --list

#확인
#kubectl -n kafka exec -ti my-kafka-0 -- /usr/bin/kafka-console-producer --broker-list my-kafka:9092 --topic erestaurant
kubectl -n kafka exec -ti my-kafka-0 -- /usr/bin/kafka-console-consumer --bootstrap-server my-kafka:9092 --topic erestaurant --from-beginning

#######################이하, Pass####################################################################
#helm del --purge my-kafka
#----------------------------
kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
위 명령어를 실행하면 아래와 같이 default storage가 두 개로 설정되는 오류가 발생

root@labs--1975389722:/home/project# kubectl get sc
NAME                        PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
azurefile                   kubernetes.io/azure-file   Delete          Immediate              true                   22h
azurefile-premium           kubernetes.io/azure-file   Delete          Immediate              true                   22h
default (default)           kubernetes.io/azure-disk   Delete          WaitForFirstConsumer   true                   22h
managed-premium (default)   kubernetes.io/azure-disk   Delete          WaitForFirstConsumer   true                   22h
#----------------------------
>>> 해결책은 아래 Command 실행
kubectl patch storageclass managed-premium -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
####################################################################################################


#========================================================================================
#소스가져오기
#========================================================================================
git clone https://github.com/choiyeonshik/e-restaurant.git

#========================================================================================
#네임스페이스 만들기
#========================================================================================
kubectl create ns choi
kubectl get ns
kubectl get all -n choi

#========================================================================================
#Deployment & Build & Push
#========================================================================================
cd /home/project/e-restaurant/hall
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/hall:v2 .
kubectl create deploy hall --image=skccuser23.azurecr.io/hall:v2 -n choi

kubectl delete deployment,pod,service hall -n choi

kubectl describe pod/hall-7cbb9cccb5-ckcd4 -n choi
kubectl logs -f pod/hall-68884b6b88-snqrs -c hall -n choi

#yaml 이용(이하, 동문)
#kubectl create -f ./kubernetes/deployment.yml -n choi
#kubectl create -f ./kubernetes/service.yaml -n choi
#kubectl apply -f ./kubernetes/deployment.yml -n choi
#kubectl apply -f ./kubernetes/service.yaml -n choi

cd /home/project/e-restaurant/kitchen
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/kitchen:v1 .
kubectl create deploy kitchen --image=skccuser23.azurecr.io/kitchen:v1 -n choi

cd /home/project/e-restaurant/payment
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/payment:v1 .
kubectl create deploy payment --image=skccuser23.azurecr.io/payment:v1 -n choi

cd /home/project/e-restaurant/workercenter
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/workercenter:v1 .
kubectl create deploy workercenter --image=skccuser23.azurecr.io/workercenter:v1 -n choi

cd /home/project/e-restaurant/gateway
mvn clean
mvn compile
mvn package

#이미지 build & push & Deploy
az acr build --registry skccuser23 --image skccuser23.azurecr.io/gateway:v1 .
kubectl create deploy gateway --image=skccuser23.azurecr.io/gateway:v1 -n choi

#확인
kubectl get all -n choi
kubectl describe pod/gateway-7cffc5cd4d-bdbhx -n choi
kubectl logs -f pod/gateway-7cffc5cd4d-bdbhx -n choi

#이후에는 apply로 처리
az acr build --registry skccuser23 --image skccuser23.azurecr.io/gateway:v1 .
#kubectl create -f ./kubernetes/deployment.yml -n choi
#kubectl create -f ./kubernetes/service.yaml -n choi
#kubectl apply -f ./kubernetes/deployment.yml -n choi
#kubectl apply -f ./kubernetes/service.yaml -n choi

kubectl expose deploy gateway --type=LoadBalancer --port=8080 -n choi

#========================================================================================
#Config Map
#========================================================================================
kubectl create configmap configmap-bikeurl --from-file=/home/project/e-restaurant/hall/kubernetes/deployment-config.yaml -n choi
#kubectl apply -f deployment-config.yaml -n choi
#kubectl create configmap configmap-bikeurl --from-literal=bikeurl=http://hall:8080 -n choi
kubectl get configmap configmap-bikeurl -o yaml -n choi

#========================================================================================
#Circuit Breaker
#========================================================================================
siege -c5 -t10S -r10 -v --content-type "application/json" 'http://20.194.44.70:8080/hall POST {"bikeid": "1", "userid": "1"}'

#========================================================================================
#무정지 재배포
#========================================================================================
kubectl get all -n choi

az acr build --registry skccuser23 --image skccuser23.azurecr.io/hall:v1 .
kubectl apply -f kubernetes/deployment.yml -n choi
kubectl get all -n choi

#========================================================================================
#기타
#========================================================================================
kubectl describe pod/nginx3-7cffc5cd4d-bdbhx -n choi

kubectl apply -f deployment-config.yaml -n choi
